<main class="main-home">
  <svg width="100%" height="100%" id="svg" viewBox="0 0 1440 590" xmlns="http://www.w3.org/2000/svg" class="transition duration-300 ease-in-out delay-150"><style>
    .path-0{
      animation:pathAnim-0 4s;
      animation-timing-function: linear;
      animation-iteration-count: infinite;
    }
    @keyframes pathAnim-0{
      0%{
        d: path("M 0,600 L 0,300 C 84.17224880382773,274.46889952153106 168.34449760765546,248.93779904306217 257,227 C 345.65550239234454,205.06220095693783 438.7942583732058,186.71770334928232 548,177 C 657.2057416267942,167.28229665071768 782.4784688995217,166.19138755980862 881,133 C 979.5215311004783,99.8086124401914 1051.291866028708,34.516746411483254 1140,7 C 1228.708133971292,-20.516746411483254 1334.354066985646,-10.258373205741627 1440,0 L 1440,600 L 0,600 Z");
      }
      25%{
        d: path("M 0,600 L 0,300 C 95.94258373205744,314.67942583732054 191.8851674641149,329.35885167464113 284,293 C 376.1148325358851,256.64114832535887 464.4019138755981,169.244019138756 571,150 C 677.5980861244019,130.755980861244 802.5071770334929,179.66507177033492 906,173 C 1009.4928229665071,166.33492822966508 1091.5693779904307,104.09569377990431 1177,66 C 1262.4306220095693,27.904306220095695 1351.2153110047848,13.952153110047847 1440,0 L 1440,600 L 0,600 Z");
      }
      50%{
        d: path("M 0,600 L 0,300 C 92.1531100478469,273.6555023923445 184.3062200956938,247.31100478468898 277,248 C 369.6937799043062,248.68899521531102 462.92822966507174,276.41148325358853 576,250 C 689.0717703349283,223.58851674641147 821.9808612440193,143.04306220095694 908,114 C 994.0191387559807,84.95693779904306 1033.1483253588515,107.41626794258373 1114,97 C 1194.8516746411485,86.58373205741627 1317.4258373205744,43.291866028708135 1440,0 L 1440,600 L 0,600 Z");
      }
      75%{
        d: path("M 0,600 L 0,300 C 72.64114832535884,318.5454545454545 145.28229665071768,337.09090909090907 260,316 C 374.7177033492823,294.90909090909093 531.5119617224882,234.18181818181816 624,189 C 716.4880382775118,143.81818181818184 744.66985645933,114.18181818181819 834,119 C 923.33014354067,123.81818181818181 1073.8086124401916,163.0909090909091 1185,149 C 1296.1913875598084,134.9090909090909 1368.0956937799042,67.45454545454545 1440,0 L 1440,600 L 0,600 Z");
      }
      100%{
        d: path("M 0,600 L 0,300 C 84.17224880382773,274.46889952153106 168.34449760765546,248.93779904306217 257,227 C 345.65550239234454,205.06220095693783 438.7942583732058,186.71770334928232 548,177 C 657.2057416267942,167.28229665071768 782.4784688995217,166.19138755980862 881,133 C 979.5215311004783,99.8086124401914 1051.291866028708,34.516746411483254 1140,7 C 1228.708133971292,-20.516746411483254 1334.354066985646,-10.258373205741627 1440,0 L 1440,600 L 0,600 Z");
      }
    }</style><defs><linearGradient id="gradient" x1="0%" y1="50%" x2="100%" y2="50%"><stop offset="5%" stop-color="#ffff00"></stop><stop offset="95%" stop-color="#00d084"></stop></linearGradient></defs><path d="M 0,600 L 0,300 C 84.17224880382773,274.46889952153106 168.34449760765546,248.93779904306217 257,227 C 345.65550239234454,205.06220095693783 438.7942583732058,186.71770334928232 548,177 C 657.2057416267942,167.28229665071768 782.4784688995217,166.19138755980862 881,133 C 979.5215311004783,99.8086124401914 1051.291866028708,34.516746411483254 1140,7 C 1228.708133971292,-20.516746411483254 1334.354066985646,-10.258373205741627 1440,0 L 1440,600 L 0,600 Z" stroke="none" stroke-width="0" fill="url(#gradient)" fill-opacity="0.53" class="transition-all duration-300 ease-in-out delay-150 path-0" transform="rotate(-180 720 300)"></path><style>
    .path-1{
      animation:pathAnim-1 4s;
      animation-timing-function: linear;
      animation-iteration-count: infinite;
    }
    @keyframes pathAnim-1{
      0%{
        d: path("M 0,600 L 0,500 C 113.04306220095694,470.7368421052631 226.08612440191388,441.4736842105263 310,428 C 393.9138755980861,414.5263157894737 448.6985645933014,416.8421052631579 530,388 C 611.3014354066986,359.1578947368421 719.1196172248805,299.1578947368421 835,278 C 950.8803827751195,256.8421052631579 1074.822966507177,274.5263157894737 1177,268 C 1279.177033492823,261.4736842105263 1359.5885167464116,230.73684210526315 1440,200 L 1440,600 L 0,600 Z");
      }
      25%{
        d: path("M 0,600 L 0,500 C 83.38755980861242,532.3636363636364 166.77511961722485,564.7272727272727 270,551 C 373.22488038277515,537.2727272727273 496.2870813397129,477.4545454545455 604,425 C 711.7129186602871,372.5454545454545 804.0765550239236,327.4545454545455 894,289 C 983.9234449760764,250.54545454545453 1071.4066985645934,218.72727272727272 1162,205 C 1252.5933014354066,191.27272727272728 1346.2966507177034,195.63636363636363 1440,200 L 1440,600 L 0,600 Z");
      }
      50%{
        d: path("M 0,600 L 0,500 C 103.08133971291866,489.21531100478467 206.16267942583733,478.4306220095694 298,478 C 389.8373205741627,477.5693779904306 470.43062200956933,487.49282296650716 575,458 C 679.5693779904307,428.50717703349284 808.1148325358853,359.5980861244019 905,342 C 1001.8851674641147,324.4019138755981 1067.11004784689,358.1148325358852 1151,343 C 1234.88995215311,327.8851674641148 1337.4449760765551,263.9425837320574 1440,200 L 1440,600 L 0,600 Z");
      }
      75%{
        d: path("M 0,600 L 0,500 C 84.36363636363635,482.63157894736844 168.7272727272727,465.2631578947368 279,463 C 389.2727272727273,460.7368421052632 525.4545454545455,473.57894736842104 625,456 C 724.5454545454545,438.42105263157896 787.4545454545454,390.421052631579 862,372 C 936.5454545454546,353.578947368421 1022.7272727272727,364.7368421052632 1121,341 C 1219.2727272727273,317.2631578947368 1329.6363636363635,258.63157894736844 1440,200 L 1440,600 L 0,600 Z");
      }
      100%{
        d: path("M 0,600 L 0,500 C 113.04306220095694,470.7368421052631 226.08612440191388,441.4736842105263 310,428 C 393.9138755980861,414.5263157894737 448.6985645933014,416.8421052631579 530,388 C 611.3014354066986,359.1578947368421 719.1196172248805,299.1578947368421 835,278 C 950.8803827751195,256.8421052631579 1074.822966507177,274.5263157894737 1177,268 C 1279.177033492823,261.4736842105263 1359.5885167464116,230.73684210526315 1440,200 L 1440,600 L 0,600 Z");
      }
    }</style><defs><linearGradient id="gradient" x1="0%" y1="50%" x2="100%" y2="50%"><stop offset="5%" stop-color="#ffff00"></stop><stop offset="95%" stop-color="#00d084"></stop></linearGradient></defs><path d="M 0,600 L 0,500 C 113.04306220095694,470.7368421052631 226.08612440191388,441.4736842105263 310,428 C 393.9138755980861,414.5263157894737 448.6985645933014,416.8421052631579 530,388 C 611.3014354066986,359.1578947368421 719.1196172248805,299.1578947368421 835,278 C 950.8803827751195,256.8421052631579 1074.822966507177,274.5263157894737 1177,268 C 1279.177033492823,261.4736842105263 1359.5885167464116,230.73684210526315 1440,200 L 1440,600 L 0,600 Z" stroke="none" stroke-width="0" fill="url(#gradient)" fill-opacity="1" class="transition-all duration-300 ease-in-out delay-150 path-1" transform="rotate(-180 720 300)"></path></svg>
  
        <h1> Introduction </h1>
        <div class="container5">
            <div class="small-div">
            
            <p>
                Our project focuses on the development of a cutting-edge machine learning algorithm designed to restore damaged images.
                Image restoration is a crucial task in computer vision and image processing, as it seeks to recover lost or deteriorated details in images, making them clearer and more visually appealing. <br>
            </p>
            <p>
                Our algorithm leverages deep learning techniques, particularly convolutional neural networks (CNNs), to learn intricate patterns
                within damaged images and predict missing or corrupted pixel values.<br>
            </p>
            </div>
            <div class="small-div">
                <p>
                This process involves a two-step approach: first, training the model on a vast dataset of pristine and damaged images to learn the underlying features of image degradation, 
                and second, applying the trained model to new, damaged images for restoration.<br></p>
                <p>
                Through this project, we aim to provide an effective and efficient solution for image restoration, 
                enhancing the quality and usability of digital images across various applications, from photography to medical imaging.
                </p>
            </div>
    </div>

    <br>
    <h1> Examples </h1>
    <div class="container5">
      <div class="small-div">
      <h2> 1.  Removing Noise from a Vintage Photograph </h2>
      <p class="p:center">
          <i> Description:</i><br>
              Imagine a vintage photograph taken decades ago, capturing a precious moment in time. Over the years, the photograph may have suffered from wear and tear, resulting in visible noise and imperfections. Our image restoration algorithm can effectively remove such noise and enhance the image, bringing back its original charm.<br>
              <br>
          </div>
          <div class="small-div">
            <i>Image Example:</i><br>
            <div class="im">
                <img src="./images/restoredimg1.jpg" alt="image 1">
            </div>
            <p> This image shows a vintage photograph with visible scratches, dust, and noise. <br>
                The restored image showcases the same photograph after applying our image restoration algorithm. The scratches, dust, and noise have been significantly reduced, revealing the details and emotions captured in the original moment.

            </p>
        </div>
      </p>
    </div>
    <br>
    <div class="container5">
      <div class="small-div">
        <h2> <b> 2. Image Inpainting </b></h2>
        <p class="p:center">
            <i>Description: <br></i>
            Inpainting is a conservation process where damaged, deteriorated, or missing parts of an artwork are filled in to present a complete image. This process is commonly used in image restoration. It can be applied to both physical and digital art mediums such as oil or acrylic paintings, chemical photographic prints, sculptures, or digital images and video.

            With its roots in physical artwork, such as painting and sculpture, traditional inpainting is performed by a trained art conservator who has carefully studied the artwork to determine the mediums and techniques used in the piece, potential risks of treatments, and ethical appropriateness of treatment.<br>
            
            <br><i> Image Example: <br></i>
            <div class="im">
                <img src="./images/Restoration2.jpg" alt="restoration2">
            </div>
            <br><br> We have two types of images: <br>
            1. Damaged<br>
            2. Masked<br>
           
      </div>     
      <div class="small-div">
            
        A masked image has the same spatial dimensions of the noise which exists in the noisy image.<br>
            <div class="image-container">
                <div class="image-box">
                    <img src="./images/restoration3.jpg" alt="Image 1">
                    <br><p> Noisy Image <br></p>
                </div>
                <div class="image-box">
                    <img src="./images/restoration4.jpg" alt="Image 2">
                    <p> With the mask </p>
                </div>
                <div class="image-box">
                    <img src="./images/restoration5.jpg" alt="image 3">
                    <p> Results </p>
                </div>
                <!-- Add more image boxes as needed -->
                
            </div>
            <br> The biggest problem with OpenCV’s image inpainting is that we need to manually input a mask for the specific image we want to fix. So how can we automate this process?

            The answer is GAN (General Adversarial Network). This paper proposes that, by using a GAN network, image inpainting can be done using neighborhood loss function and gradient loss with a better quality restored image.  <br>
        </p>
          </div> 
      </div> 
  
            
    <br>    
    
    <div class="container5">
      <div class="small-div">
      <h2><b> 3. Pixelation </b></h2>
      <p class="p:center">
          Pixelation is a visual effect or image processing technique where an image is displayed or modified in such a way that individual pixels, which are the smallest units of an image, become clearly visible. This results in a blocky, low-resolution appearance, as opposed to a smooth and detailed one.</div>
        <div class="small-div">
          a. Pixel <br>
          b. Causes of pixelation<br>
          c. Creative uses <br>
          d. Privacy and Cebsirship <br>
          e. Digital Forensic <br>
          f. Image Processing <br>
          g. Anti-ALliasianing <br>
          h. Resolution 
      </div>  
     </div> 
     <div class="container5">
      <div class="small-div">
        <br>
        Here's a more detailed explanation of pixelation:
        <br>
        a. <b>Pixel:</b><br> A pixel, short for "picture element," is the smallest unit of a digital image. It is a tiny square or dot that represents a single color. When you look closely at a digital image, you can see individual pixels.
        <br><br>
        b. <b>Causes of Pixelation:</b><br>
        - <b>Zooming In:</b> When you zoom in on a digital image, the individual pixels become more prominent. This is especially noticeable if the image has a low resolution to begin with. <br>
        - <b>Resizing:</b> Enlarging a small image can lead to pixelation because you are stretching the available pixels, causing a loss of detail.<br>
        - <b>Mosaic Effect:</b> In image editing software, the pixelation effect can be intentionally applied to an image as a creative or privacy measure. This is often referred to as the "mosaic" effect.<br>
        <br>
        c. <b>Creative Uses:</b><br>
        - <b>Pixel Art:</b> Pixelation is intentionally used in a style of digital art called "pixel art." In pixel art, images are created by hand-placing individual pixels to form detailed and often retro-style artwork.<br>
        - <b>Video Games</b> Many classic video games used pixel art as a design choice due to the limited graphical capabilities of older gaming systems.<br>
        <br>
        d.<b>Privacy and Censorship:</b> <br> Pixelation is sometimes used for privacy reasons, such as blurring faces or obscuring sensitive information in images or videos. This is often done to maintain anonymity.<br>

      </div>
      <div class="small-div">
        <br>
        e. <b>Digital Forensics:</b><br> In forensic investigations, pixelation can be used to protect the identities of individuals in images while preserving the rest of the visual data.<br>
        <br>
        f. <b>Image Processing:</b><br> In image processing and computer vision, pixelation can be a side effect of certain operations like image compression and resizing. It can also be a technique used for image concealment.<br>
        <br>
        g. <b>Anti-Aliasing:</b><br> Anti-aliasing is a technique used to reduce pixelation and smooth out jagged edges in digital images, making them appear less blocky and more visually appealing. It works by blending colors at the edges of objects to create a smoother transition between pixels.
        <br><br>
        h. <b>Resolution:</b><br> The level of pixelation in an image is often associated with its resolution. Higher resolution images have more pixels per unit area and thus appear smoother, while lower resolution images have fewer pixels and can exhibit more obvious pixelation.
        <br> <br>
        In summary, pixelation is a visual effect characterized by the display or modification of an image at a low resolution, causing individual pixels to become visible. It can be both an unintentional side effect and an intentional creative or privacy measure in digital imagery.
    </p>
    </div>
    <br>
    </div>
       <h2>Hybrid Machine Learning Algorithm</h2>
    <p class="p:center">
        The term "hybrid machine learning algorithm" typically refers to an approach that combines elements from different types of machine learning algorithms to achieve improved performance or address specific challenges. It involves integrating techniques from different categories, such as traditional (non-machine learning) methods and modern machine learning approaches, like deep learning.
        The hybrid machine learning algorithm utilizes both supervised and unsupervised techniques for better accuracy.
        <br><br>
        In the context of image     restoration, a hybrid machine learning algorithm could combine traditional image processing techniques with deep learning methods. For instance, using classical image processing methods to address certain degradation aspects and then leveraging a deep learning model, trained on a diverse dataset, to enhance the overall restoration process.
        <br><br>
        The hybrid approach acknowledges the strengths of both traditional methods and modern machine learning techniques, aiming to create a more robust and versatile solution for specific tasks. It's important to note that the specific design and components of a hybrid algorithm depend on the nature of the problem being addressed and the characteristics of the data.
        <br><br>
        In our innovative image restoration methodology, we employ a comprehensive mix of machine learning algorithms to enhance the quality of degraded images.
        
        <br>This amalgamation includes leveraging advanced techniques such as grayscale transformations like <b>Convolutional Neural Networks(CNNs)</b>and <b>Deep Neural Networks (DNNs)</b> where models discern grayscale information to bring out nuanced details.
        <br><br>
        Additionally, resizing algorithms like <b>Generative Adversarial Networks (GANs) </b>are employed to adjust image dimensions intelligently. 
    
        <br>For addressing blurriness, sophisticated algorithms inspired by  are <b>Deconvolutional Neural Networks</b>, <b>Weiner Filter</b>, <b>Deep Image Prior</b>, integrated, enabling the restoration of sharp features. 
        <br><br>
        Pixelation, often encountered in degraded images, is effectively tackled using <b>Super-Resolution Convolutional Neural Networks (SRCNN)</b>, <b>Generative Adversarial Networks (GANs)</b>, <b>Non-Local Means Denoising</b> ,ensuring a refined output. 
        <br><br>
        Our approach extends beyond these specific techniques, incorporating a diverse set of machine learning algorithms, each tailored to address distinct facets of image degradation. This holistic strategy aims to provide a comprehensive and effective solution for image restoration.
    </p>

    <h2> Machine Learning algorithms for restoring images </h2>
    <p class="p:center">
            There are several machine learning algorithms and techniques used for restoring and enhancing images. These algorithms are commonly used in image processing tasks to remove noise, increase resolution, improve quality, and restore damaged or degraded images. Here are some popular machine learning algorithms and methods for image restoration:<br> <br>

    1. <b>Denoising Autoencoders</b>:<br> Autoencoders are neural networks used for dimensionality reduction. Variants like Denoising Autoencoders are used to remove noise from images. <br> <br>

    2. <b>Convolutional Neural Networks (CNNs)</b>:<br> CNNs are commonly used for image restoration tasks, including denoising, super-resolution, and inpainting. Variants of CNNs such as U-Net and Deep Residual Networks (ResNets) are popular choices. <br> <br>

    3. <b>Super-Resolution Convolutional Neural Networks (SRCNN)</b>:<br> SRCNN is a specific CNN architecture designed for single-image super-resolution, i.e., increasing the resolution of an image. <br> <br>

    4. <b>Generative Adversarial Networks (GANs)</b>:<br> GANs are used for a wide range of image restoration tasks. Variants like DCGAN and SRGAN are used for tasks such as super-resolution and denoising. <br> <br>

    5. <b>Bilateral Filters</b>:<br> These filters are used to reduce noise while preserving edges in images. They are not deep learning models but are effective for noise reduction. <br> <br>

    6. <b>Non-Local Means Denoising</b>:<br> This algorithm calculates the weighted average of pixel values, which helps in denoising images.<br><br>

    7. <b>Total Variation (TV) Regularization</b>:<br> TV regularization is used to reduce noise and preserve edges in images. It's often used in optimization-based approaches.<br><br>

    8. <b>BM3D (Block-Matching and 3D Filtering)</b>:<br> BM3D is a popular non-local denoising method that operates in 3D groups of similar patches.<br><br>

    9. <b>Wavelet Transform</b>:<br> Wavelet-based image restoration methods use multi-resolution analysis for noise reduction and feature preservation.<br><br>

    10. <b>Singular Value Decomposition (SVD)</b>:<br> SVD is used in some image restoration techniques for noise reduction and resolution enhancement. <br><br>

    11. <b>Dictionary Learning</b>:<br> Techniques like K-SVD and BM3D use dictionary learning for image denoising and restoration.<br><br>

    12. <b>Non-Local Inpainting</b>:<br> Non-local inpainting algorithms fill in missing or damaged regions of an image based on non-local similarities. <br><br>

    13. <b>Deep Image Prior (DIP)</b>:<br> DIP is a recent approach that uses the structure of deep neural networks to restore images without requiring a specific dataset. <br><br>

    14. <b>Low-Rank Matrix Recovery</b>: <br> These techniques aim to recover a low-rank approximation of the image matrix, which can help in removing noise. <br><br>

    The choice of algorithm depends on the specific image restoration task and the nature of the images you're working with. Different algorithms may perform better in different scenarios. It's common to experiment with multiple methods to determine which one works best for your particular application. <br>
    </p>
    <br>
    <h2> Process </h2>
    <div class="container5">
      <div class="small-div">
            <h3 class="h3-home"><b><u>Step 1: Image Acquisition</u></b></h3>
            
            Image restoration begins with acquiring the damaged or degraded image through a digital camera, scanner, or any other imaging device. This acquired image may suffer from various types of degradation, such as noise, blurriness, or missing data.
            <br><br>
           <h3 class="h3-home"><b><u>Step 2: Image Degradation Model</u></b></h3>
           <p class="p:center">
            To restore an image, it's crucial to understand how it has been degraded. Image degradation typically occurs due to various factors, including:
            <br><br>
            
                -<b>Noise:</b> Random variations in pixel values that can result from sensor limitations or transmission errors.<br>
                - <b>Blur:</b>Loss of sharpness due to motion, defocusing, or optical imperfections.<br>
                - <b>Missing Data (Inpainting):</b> Areas of the image might be missing or corrupted, and they need to be filled in.<br>
                <br>
            
                Mathematically modeling these degradation processes is essential to develop effective restoration methods.<br>
                <br>
            </p>
            <h3 class="h3-home"><b><u>Step 3: Restoration Algorithm</u></b></h3>

            <p class="p:center">
                Image restoration algorithms aim to reverse the effects of degradation by applying mathematical operations to the degraded image. The specific algorithm chosen depends on the type and extent of degradation. Common restoration tasks include:
                <br><br>
                - <b>Denoising:</b> Removing noise from an image, typically done using filters or deep learning techniques.<br>
                - <b>Deblurring:</b> Restoring sharpness by reversing the blur effect using deconvolution techniques.<br>
                - <b>Inpainting:</b> Filling in missing or corrupted parts of an image based on the surrounding information. This can be done using methods like texture synthesis or deep learning.<br>

                The choice of the algorithm can vary, ranging from traditional signal processing methods to more advanced machine learning and deep learning techniques.
                <br><br>
            </p>
            <h3 class="h3-home"><b><u>Step 4: Preprocessing</u></b></h3>

            <p class="p:center">
                Before applying the restoration algorithm, some preprocessing may be necessary. This can involve tasks like:<br>
                <br>
                - <b>Resizing:</b> Adjusting the image size if needed. <br>
                - <b>Normalization:</b> Scaling pixel values to a standard range, such as [0, 1] or [-1, 1]. <br>
                <br>
            </p>
      </div>
      <div class="small-div">
            <h3 class="h3-home"><b><u>Step 5: Application of the Restoration Algorithm</u></b></p></h3>
            <p class="p:center"> 
                The restoration algorithm is applied to the degraded image to produce a restored image. Depending on the algorithm, this process can involve mathematical operations, filtering, convolution, or deep learning computations.
                <br><br>
                - For denoising, algorithms typically emphasize the underlying structure of the image while suppressing noise. <br>
                - For deblurring, deconvolution techniques aim to reverse the blurring effect. <br>
                - For inpainting, the algorithm fills in missing or corrupted areas based on surrounding information.<br>
                <br>
            </p>
            <h3 class="h3-home"><b><u>Step 6: Postprocessing</u></b></h3>
            <p class="p:center">
                After restoration, the resulting image may undergo postprocessing to further enhance its quality. This can include tasks like contrast adjustment, sharpening, or color correction.
                <br><br>
            </p>
            <h3 class="h3-home"><b><u>Step 7: Evaluation</u></b></h3>
            <p>
                To assess the quality of the restored image, various metrics and visual inspection are used. Common metrics include Mean Squared Error (MSE), Structural Similarity Index (SSIM), or Peak Signal-to-Noise Ratio (PSNR). Visual inspection is crucial to ensure that the visual quality of the image meets the desired standards.
                <br> <br>
            </p>
            <h3 class="h3-home"><b><u>Step 8: Application and Use</u></b></h3>
            <p class="p:center">
                Once the image is successfully restored, it can be used for various purposes, such as:
                <br>
                - Image enhancement in photography<br>
                - Medical image analysis<br>
                - Satellite image processing<br>
                - Digital art restoration<br>
                - Forensic image analysis<br>
                <br>
                The choice of restoration techniques and the complexity of the process depend on the specific application and the type of degradation that needs to be addressed.<br>
            </p>
      </div>
        
        
    </div>
    
    <div class="try-it-out-button">
        <a href="Restoration.html" class="try-it-out-link">Try It Out</a>
    </div>
</main>